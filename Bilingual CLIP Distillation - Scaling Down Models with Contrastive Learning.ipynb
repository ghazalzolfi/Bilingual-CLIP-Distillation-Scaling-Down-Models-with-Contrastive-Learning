{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be138f6f",
      "metadata": {
        "id": "be138f6f",
        "papermill": {
          "duration": 0.02181,
          "end_time": "2024-12-18T17:13:30.324107",
          "exception": false,
          "start_time": "2024-12-18T17:13:30.302297",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Knowdge Distillation using Contrastive Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "376ecc79",
      "metadata": {
        "id": "376ecc79",
        "papermill": {
          "duration": 0.014958,
          "end_time": "2024-12-18T17:13:30.355437",
          "exception": false,
          "start_time": "2024-12-18T17:13:30.340479",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        " #### Student Name: Ghazal Zolfi Moselo\n",
        "\n",
        "\n",
        " #### Student ID: 401104146\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1dba4d2",
      "metadata": {
        "id": "a1dba4d2",
        "papermill": {
          "duration": 0.014965,
          "end_time": "2024-12-18T17:13:30.385132",
          "exception": false,
          "start_time": "2024-12-18T17:13:30.370167",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "In this exercise, we aim to distill knowledge from a large monolingual model into a smaller multilingual model using contrastive learning, specifically leveraging the CLIP model loss.\n",
        "\n",
        "We employ a small paired English-Persian dataset to define the loss pairs for our CLIP training. Given the substantial dataset size and batch size typically required for CLIP's loss computation (exceeding 19,000 samples per batch in standard tasks), which is impractical for our setup on Colab, we use a reduced batch size to focus on learning the procedure rather than achieving optimal performance, so we don't expect actual real-world results, only the training prcodure."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90e95f9e",
      "metadata": {
        "id": "90e95f9e",
        "papermill": {
          "duration": 0.014841,
          "end_time": "2024-12-18T17:13:30.414686",
          "exception": false,
          "start_time": "2024-12-18T17:13:30.399845",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "CLIP (Contrastive Language-Image Pretraining) is a foundational model introduced by OpenAI to bridge the gap between text and image modalities. By aligning text descriptions and corresponding images in a shared embedding space, CLIP achieves remarkable zero-shot generalization capabilities across a wide range of tasks. It is trained on a massive dataset of image-text pairs using contrastive loss, ensuring that image embeddings align closely with their corresponding textual descriptions while remaining distinct from unrelated samples. This cross-modal alignment enables CLIP to perform tasks like image retrieval, captioning, and classification with minimal fine-tuning.\n",
        "\n",
        "The CLIP loss plays a crucial role in training the model by implementing a cross-entropy loss function in the contrastive learning framework. This loss operates on paired data, where each image-text pair is treated as a positive match, while all other pair combinations in the batch are considered negatives. The loss ensures that positive pairs receive high similarity scores, while negatives are penalized. However, achieving optimal results with CLIP loss often requires large batch sizes to provide sufficient negative samples, which can be computationally intensive. This makes training with limited resources challenging, necessitating adaptations such as smaller batch sizes or alternative strategies to approximate the training dynamics.\n",
        "\n",
        "\n",
        "Knowledge distillation is a technique used in machine learning to transfer knowledge from a large, complex model (the \"teacher\") to a smaller, more efficient model (the \"student\"). The primary goal of this process is to retain the performance and accuracy of the larger model while significantly reducing computational and memory requirements. This is achieved by training the student model to mimic the outputs of the teacher model, often through techniques such as matching soft probability distributions or intermediate representations. Knowledge distillation has become an essential approach in deploying machine learning models on resource-constrained devices such as smartphones and edge devices.\n",
        "\n",
        "In practice, knowledge distillation is not limited to replicating predictions; it can also involve transferring knowledge about internal features or learned representations.\n",
        "\n",
        "\n",
        "### Challenges in Resource-Constrained Settings\n",
        "CLIP’s reliance on large-scale datasets and batch sizes makes direct implementation computationally demanding. This exercise demonstrates an adaptation of the process, reducing batch size and dataset size to provide a practical understanding of the training procedure. While this approach sacrifices performance and real-world applicability, it highlights the mechanics of using CLIP loss for contrastive learning and lays the foundation for extending the process to larger datasets and batch sizes in future applications.\n",
        "\n",
        "\n",
        "\n",
        "### About CLIP and Contrastive Learning\n",
        "CLIP, developed by OpenAI, bridges the gap between text and image modalities by aligning corresponding embeddings in a shared space. It leverages contrastive loss to train on image-text pairs, ensuring that embeddings of positive pairs (e.g., an image and its corresponding caption) are highly similar, while embeddings of unrelated pairs remain distinct. The cross-entropy-based contrastive loss evaluates the similarity between positive pairs while penalizing mismatches for all other combinations within a batch.\n",
        "\n",
        "### Key aspects of CLIP loss include:\n",
        "\n",
        "- Positive Pairing: Encourages high similarity scores for embeddings of paired text and image data.\n",
        "- Negative Sampling: Penalizes mismatched pairs within the batch, requiring large batch sizes for effective performance due to the need for a diverse set of negative samples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba7c7274",
      "metadata": {
        "id": "ba7c7274",
        "papermill": {
          "duration": 0.01457,
          "end_time": "2024-12-18T17:13:30.444777",
          "exception": false,
          "start_time": "2024-12-18T17:13:30.430207",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## !!! Note !!! You Should Answer to all the TODOs\n",
        "\n",
        "Also feel free to ask your questions on Quera."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7da461e",
      "metadata": {
        "id": "e7da461e",
        "papermill": {
          "duration": 0.014905,
          "end_time": "2024-12-18T17:13:30.474341",
          "exception": false,
          "start_time": "2024-12-18T17:13:30.459436",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "\n",
        "\n",
        "## Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06e48967",
      "metadata": {
        "id": "06e48967",
        "papermill": {
          "duration": 0.014958,
          "end_time": "2024-12-18T17:13:30.503840",
          "exception": false,
          "start_time": "2024-12-18T17:13:30.488882",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "We install Required Packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "69339c7a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:13:30.535983Z",
          "iopub.status.busy": "2024-12-18T17:13:30.535604Z",
          "iopub.status.idle": "2024-12-18T17:13:50.781819Z",
          "shell.execute_reply": "2024-12-18T17:13:50.781004Z"
        },
        "id": "69339c7a",
        "outputId": "3cc79e61-61a6-4f59-c59c-acec86d42d8d",
        "papermill": {
          "duration": 20.264414,
          "end_time": "2024-12-18T17:13:50.783672",
          "exception": false,
          "start_time": "2024-12-18T17:13:30.519258",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MVx_gIkX4tQ8ya2OsHt0mqLmw1Pf2CcK\n",
            "To: /content/train.csv\n",
            "100% 7.35M/7.35M [00:00<00:00, 138MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Co-dwJfWw-C_ral0hoAS_X94wN-_vbCj\n",
            "To: /content/val.csv\n",
            "100% 2.45M/2.45M [00:00<00:00, 200MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gdown\n",
        "!gdown \"https://drive.google.com/uc?id=1MVx_gIkX4tQ8ya2OsHt0mqLmw1Pf2CcK\"\n",
        "!gdown \"https://drive.google.com/uc?id=1Co-dwJfWw-C_ral0hoAS_X94wN-_vbCj\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "70d93c5e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:13:50.816136Z",
          "iopub.status.busy": "2024-12-18T17:13:50.815755Z",
          "iopub.status.idle": "2024-12-18T17:14:15.313938Z",
          "shell.execute_reply": "2024-12-18T17:14:15.312837Z"
        },
        "id": "70d93c5e",
        "outputId": "f4e1c127-d4f7-4d38-eacf-90af7fea2028",
        "papermill": {
          "duration": 24.516699,
          "end_time": "2024-12-18T17:14:15.316512",
          "exception": false,
          "start_time": "2024-12-18T17:13:50.799813",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.1.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-16d6a20cb021>:4: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  import pkg_resources\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "open-clip-torch (2.30.0) is installed\n",
            "pandas (2.2.2) is installed\n",
            "numpy (1.26.4) is installed\n",
            "matplotlib (3.10.0) is installed\n",
            "transformers (4.47.1) is installed\n",
            "tqdm (4.67.1) is installed\n",
            "torch (2.5.1+cu121) is installed\n",
            "datasets (3.2.0) is installed\n"
          ]
        }
      ],
      "source": [
        "!pip install setuptools\n",
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "def installPackages(packages):\n",
        "    def installPackage(package):\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "    for package in REQUIRED_PACKAGES:\n",
        "        try:\n",
        "            dist = pkg_resources.get_distribution(package)\n",
        "            print('{} ({}) is installed'.format(dist.key, dist.version))\n",
        "        except pkg_resources.DistributionNotFound:\n",
        "            print('{} is NOT installed'.format(package))\n",
        "            installPackage(package)\n",
        "            print('{} was successfully installed.'.format(package))\n",
        "\n",
        "REQUIRED_PACKAGES = [\n",
        "    'open_clip-torch',\n",
        "    'pandas',\n",
        "    'numpy',\n",
        "    'matplotlib',\n",
        "    'transformers',\n",
        "    'tqdm',\n",
        "    'torch',\n",
        "    'datasets',\n",
        "]\n",
        "\n",
        "installPackages(REQUIRED_PACKAGES)\n",
        "\n",
        "import gc\n",
        "import itertools\n",
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "import random\n",
        "import string\n",
        "import uuid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import open_clip\n",
        "from open_clip import model as TE\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from datasets import load_dataset, Dataset, Features, Array2D, Value\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModel, TFAutoModel\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4c39c86",
      "metadata": {
        "id": "f4c39c86",
        "papermill": {
          "duration": 0.01563,
          "end_time": "2024-12-18T17:14:15.349709",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.334079",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Beware to use cuda for training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fd519039",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:15.383716Z",
          "iopub.status.busy": "2024-12-18T17:14:15.383220Z",
          "iopub.status.idle": "2024-12-18T17:14:15.388059Z",
          "shell.execute_reply": "2024-12-18T17:14:15.387180Z"
        },
        "id": "fd519039",
        "papermill": {
          "duration": 0.024557,
          "end_time": "2024-12-18T17:14:15.389794",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.365237",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def getDevice(which=\"cuda:0\", yellAtCpu=True):\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(which)\n",
        "    else:\n",
        "        if yellAtCpu:\n",
        "             raise Exception(\"I won't run on CPU!\")\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    return device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67a2eff9",
      "metadata": {
        "id": "67a2eff9",
        "papermill": {
          "duration": 0.016217,
          "end_time": "2024-12-18T17:14:15.422727",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.406510",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Configs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75c787a8",
      "metadata": {
        "id": "75c787a8",
        "papermill": {
          "duration": 0.016978,
          "end_time": "2024-12-18T17:14:15.455652",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.438674",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "These are our training configurations, read them!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "802d832e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:15.503624Z",
          "iopub.status.busy": "2024-12-18T17:14:15.503324Z",
          "iopub.status.idle": "2024-12-18T17:14:15.590038Z",
          "shell.execute_reply": "2024-12-18T17:14:15.589056Z"
        },
        "id": "802d832e",
        "papermill": {
          "duration": 0.11541,
          "end_time": "2024-12-18T17:14:15.591685",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.476275",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def Configs():\n",
        "    return {\n",
        "        \"device\": getDevice(),\n",
        "        \"reference_checkPoint\" : \"EVA02-E-14-plus\",                # teacher\n",
        "        \"candidate_checkpoint\" : \"setu4993/smaller-LaBSE\",         # student\n",
        "        \"train_path\" : \"train.csv\",\n",
        "        \"val_path\" : \"val.csv\",\n",
        "        \"save_path\" : \"./best-model.pth\",\n",
        "        \"english\" : \"en\",                                         # dont mind them\n",
        "        \"persian\" : \"fa\",\n",
        "        \"batch_size\": 128,                                        # should have been really big, but we can't here\n",
        "        \"lr\": 1e-4,\n",
        "        \"epochs\": 5,                                               # 40 minute per epoch\n",
        "        \"tok_percentile\" : 99,\n",
        "        \"temperature\": 20,\n",
        "        \"dropout\": 0.05,\n",
        "        \"unfreezed_layers\" : 10,\n",
        "        \"weight_decay\": 1e-5,\n",
        "        \"patience\": 1,\n",
        "        \"factor\" : 0.8,\n",
        "        \"reference_embedding\": 1024,                               # DONT MIND THESE\n",
        "        \"reference_context_length\" : 77,\n",
        "        \"reference_vocab_size\" : 49408,\n",
        "        \"reference_heads\" : 20,\n",
        "        \"reference_width\" : 1280,\n",
        "        \"reference_layers\" : 32,\n",
        "        \"cls_token_index\" : 0,\n",
        "        \"project_to\" : 1024,\n",
        "    }\n",
        "\n",
        "configs = Configs()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b95e360",
      "metadata": {
        "id": "7b95e360",
        "papermill": {
          "duration": 0.015595,
          "end_time": "2024-12-18T17:14:15.623791",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.608196",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Question Box\n",
        "### TODO (10pts)\n",
        "1- Why do we use temperature in training using contrastive learning?\n",
        "\n",
        "Temperature is used in contrastive learning to scale the logits (similarity scores) before applying the softmax function. Its primary purposes are:\n",
        "\n",
        "**Balancing sensitivity:** A lower temperature sharpens the probability distribution, making the model focus more on highly similar pairs, while a higher temperature smooths the distribution, emphasizing a broader range of pairs.\n",
        "\n",
        "**Improving convergence:** Temperature helps control how aggressively the model updates during training. A well-chosen temperature can enhance gradient flow and stabilize learning.\n",
        "\n",
        "---\n",
        "\n",
        "2- Why do we need to freeze some layers of a model? mention 2 reasons.\n",
        "\n",
        "**Preserving pretrained knowledge:** Freezing some layers, especially in transfer learning, helps retain knowledge from a pretrained model. This is particularly useful when the pretrained layers capture general features that are already well-suited to the task at hand, such as edge detection in images or fundamental language structures in NLP.\n",
        "\n",
        "**Reducing computational cost and overfitting:** Freezing layers reduces the number of parameters being updated, lowering the computational requirements and minimizing the risk of overfitting, especially when training on small datasets.\n",
        "\n",
        "---\n",
        "\n",
        "3- Read the whole code and find out what tok_percentile is used for.\n",
        "\n",
        "`tok_percentile` is likely used to determine a threshold based on a percentile value of a dataset or a set of numerical values, often for filtering or selecting elements. For instance:\n",
        "\n",
        "- It might be calculated to identify a cutoff value in a distribution of token importance scores or feature weights, such as selecting the top-k% most significant tokens.\n",
        "- It could be used to filter out less relevant tokens in a sequence or to prioritize processing based on importance.\n",
        "\n",
        "To provide a more specific answer, the actual implementation of `tok_percentile` needs to be examined in the code to determine the context in which it is applied. If it is computed using a function like `np.percentile`, it extracts a value below which a given percentage of the data falls.\n",
        "\n",
        "### Example of `tok_percentile` Usage in Code\n",
        "If the code snippet looks something like this:\n",
        "```python\n",
        "tok_percentile = np.percentile(token_scores, 90)\n",
        "important_tokens = tokens[token_scores > tok_percentile]\n",
        "```\n",
        "This indicates that `tok_percentile` is being used to filter out the top 10% of tokens based on their importance scores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a9cfd8b",
      "metadata": {
        "id": "6a9cfd8b",
        "papermill": {
          "duration": 0.015679,
          "end_time": "2024-12-18T17:14:15.655199",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.639520",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Data and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5d84bc5a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:15.689321Z",
          "iopub.status.busy": "2024-12-18T17:14:15.688449Z",
          "iopub.status.idle": "2024-12-18T17:14:15.700724Z",
          "shell.execute_reply": "2024-12-18T17:14:15.699987Z"
        },
        "id": "5d84bc5a",
        "papermill": {
          "duration": 0.031369,
          "end_time": "2024-12-18T17:14:15.702439",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.671070",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def getDatasetsCSV(prevEnCol, prevFaCol, newEnCol, newFaCol, trainPath, valPath):\n",
        "    df = pd.read_csv(trainPath)\n",
        "    dfVal = pd.read_csv(valPath)\n",
        "\n",
        "    if df.empty:\n",
        "        raise ValueError(\"Training dataset is empty or missing\")\n",
        "\n",
        "    if dfVal.empty:\n",
        "        raise ValueError(\"Validation dataset is empty or missing\")\n",
        "\n",
        "    dfTraind = df.loc[:, [prevEnCol, prevFaCol]].rename(columns={prevEnCol: newEnCol, prevFaCol: newFaCol})\n",
        "    dfVal = dfVal.loc[:, [prevEnCol, prevFaCol]].rename(columns={prevEnCol: newEnCol, prevFaCol: newFaCol})\n",
        "\n",
        "    datasetTrain = Dataset.from_pandas(dfTraind)\n",
        "    datasetVal = Dataset.from_pandas(dfVal)\n",
        "\n",
        "    return datasetTrain, datasetVal\n",
        "\n",
        "def getDsByLang(persianCol, englishCol):\n",
        "    def getPersianDs(dataset):\n",
        "        return dataset[persianCol]\n",
        "\n",
        "    def getEnglishDs(dataset):\n",
        "        return dataset[englishCol]\n",
        "\n",
        "    getPersianDs.label = persianCol\n",
        "    getEnglishDs.label = englishCol\n",
        "\n",
        "    return getPersianDs, getEnglishDs\n",
        "\n",
        "class Normalizer():\n",
        "    def __init__(self):\n",
        "        translation_src = ' ىكي“”0123456789%إأآئيؤةك'\n",
        "        translation_dst = ' یکی\"\"۰۱۲۳۴۵۶۷۸۹٪اااییوهک'\n",
        "\n",
        "        self.translations = str.maketrans(translation_src, translation_dst)\n",
        "\n",
        "        patterns = [\n",
        "            (r' {2,}', ' '),  # remove extra spaces\n",
        "            (r'\\n+', ' '),  # replace newlines with space\n",
        "            (r'\\u200c+', ' '),  # replace ZWNJs with space\n",
        "            (r'[ـ\\r]', '')  # remove keshide, carriage returns\n",
        "        ]\n",
        "\n",
        "        self.character_refinement_patterns = [(re.compile(pattern), repl) for pattern, repl in patterns]\n",
        "\n",
        "    def normalizeFa(self, text):\n",
        "        text = text.lower().translate(self.translations)\n",
        "        text = re.sub('[^a-zA-Z۰-۹آ-ی ]', ' ', text)\n",
        "\n",
        "        for pattern, repl in self.character_refinement_patterns:\n",
        "            text = pattern.sub(repl, text)\n",
        "        return text.strip()\n",
        "\n",
        "    def normalizeEn(self, text):\n",
        "        text = text.lower()\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation)) # Remove punctuation\n",
        "        return text\n",
        "\n",
        "def applyPreprocess(datasets, configs=configs, Normalizer=Normalizer):\n",
        "    def applyRowNormalization(example):\n",
        "        example[configs['persian']] = normalizer.normalizeFa(example[configs['persian']])\n",
        "        example[configs['english']] = normalizer.normalizeEn(example[configs['english']])\n",
        "\n",
        "        return example\n",
        "\n",
        "    normalizer = Normalizer()\n",
        "\n",
        "    newDatasets = []\n",
        "    for dataset in datasets:\n",
        "        newDatasets.append(dataset.map(applyRowNormalization))\n",
        "\n",
        "    return newDatasets\n",
        "\n",
        "def preprocessSentence(text, lang, mostFreq=None, Normalizer=Normalizer, configs=configs):\n",
        "    normalizer = Normalizer()\n",
        "    if lang == configs['persian']:\n",
        "        normalized = normalizer.normalizeFa(text)\n",
        "    elif lang == configs['english']:\n",
        "        normalized = normalizer.normalizeEn(text)\n",
        "    else:\n",
        "        raise ValueError(\"Not supported lang\")\n",
        "\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86190e87",
      "metadata": {
        "id": "86190e87",
        "papermill": {
          "duration": 0.016557,
          "end_time": "2024-12-18T17:14:15.735930",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.719373",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Utils\n",
        "### TODO: Complete these Utility functions (10pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7b0c992a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:15.771618Z",
          "iopub.status.busy": "2024-12-18T17:14:15.771362Z",
          "iopub.status.idle": "2024-12-18T17:14:15.776968Z",
          "shell.execute_reply": "2024-12-18T17:14:15.776216Z"
        },
        "id": "7b0c992a",
        "papermill": {
          "duration": 0.025354,
          "end_time": "2024-12-18T17:14:15.778667",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.753313",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def getClsToken(tensor, configs=configs):\n",
        "    \"\"\"\n",
        "    Extracts the classification (CLS) token from the input tensor.\n",
        "\n",
        "    Parameters:\n",
        "        tensor (torch.Tensor): The input tensor of shape (batch_size, seq_length, hidden_dim).\n",
        "        configs (dict): A dictionary containing configuration settings. Must include the key \"cls_token_index\"\n",
        "                        which specifies the index of the CLS token in the sequence dimension.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor containing the CLS token for each example in the batch,\n",
        "                      of shape (batch_size, 1, hidden_dim).\n",
        "    \"\"\"\n",
        "    clsId = configs[\"cls_token_index\"]\n",
        "    return tensor[:, clsId, :]\n",
        "\n",
        "def flattenMiddle(tensor):\n",
        "    \"\"\"\n",
        "    Flattens the middle dimension (sequence length) of the input tensor, removing it.\n",
        "\n",
        "    Parameters:\n",
        "        tensor (torch.Tensor): The input tensor of shape (batch_size, seq_length, hidden_dim).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor of shape (batch_size, hidden_dim) with the middle dimension flattened out.\n",
        "    \"\"\"\n",
        "    return tensor.squeeze(1)\n",
        "\n",
        "def freezeModel(model):\n",
        "    \"\"\"\n",
        "    Freeze all parameters of a given model.\n",
        "    Parameters:\n",
        "        model (torch.nn.Module): The PyTorch model whose parameters are to be frozen.\n",
        "    \"\"\"\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2489bf4f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:15.813785Z",
          "iopub.status.busy": "2024-12-18T17:14:15.813542Z",
          "iopub.status.idle": "2024-12-18T17:14:15.820975Z",
          "shell.execute_reply": "2024-12-18T17:14:15.820275Z"
        },
        "id": "2489bf4f",
        "papermill": {
          "duration": 0.026945,
          "end_time": "2024-12-18T17:14:15.822548",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.795603",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def plotMetric(metricData, metricName):\n",
        "    if metricName == None or metricName not in metricData:\n",
        "        raise ValueError(\"No such metric\")\n",
        "    metricData[metricName].plot()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metricName)\n",
        "    plt.title(f'Plot of {metricName}')\n",
        "    plt.show()\n",
        "\n",
        "threshold=1\n",
        "def calcPrcentileTokens(dataset, tokenizer, field, percentile=configs[\"tok_percentile\"], thershold=1):\n",
        "    \"\"\"\n",
        "    Calculate the token length at a specific percentile for a dataset field.\n",
        "\n",
        "    This function tokenizes the data in the specified field of the dataset and calculates\n",
        "    the token length at the given percentile. An optional threshold can be added to the result.\n",
        "\n",
        "    Parameters:\n",
        "        dataset (dict or Dataset): The dataset containing the data to be tokenized.\n",
        "        tokenizer (callable): A tokenizer function or object with a callable interface\n",
        "                              (e.g., HuggingFace tokenizer).\n",
        "        field (str): The field in the dataset whose token lengths are to be calculated.\n",
        "        percentile (float, optional): The percentile to compute (default is the value in\n",
        "                                       `configs[\"tok_percentile\"]`).\n",
        "        thershold (int, optional): A value to add to the calculated percentile token length\n",
        "                                    (default is 1).\n",
        "\n",
        "    Returns:\n",
        "        int: The token length at the specified percentile plus the threshold.\n",
        "\n",
        "    Raises:\n",
        "        KeyError: If the specified field does not exist in the dataset.\n",
        "        TypeError: If `tokenized` is not in the expected format.\n",
        "\n",
        "    Example:\n",
        "        dataset = {\"text\": [\"This is a sentence.\", \"Another example sentence.\"]}\n",
        "        tokenizer = lambda x: {\"input_ids\": [[1, 2, 3, 4], [5, 6, 7, 8, 9]]}\n",
        "        field = \"text\"\n",
        "        calcPrcentileTokens(dataset, tokenizer, field, percentile=95, thershold=2)\n",
        "\n",
        "    Notes:\n",
        "        - If the tokenized output is a dictionary (e.g., HuggingFace tokenizers), it assumes\n",
        "          that `input_ids` contains the token sequences.\n",
        "        - If the tokenized output is a tensor, nonzero token counts are used to determine lengths.\n",
        "    \"\"\"\n",
        "    tokenized = tokenizer(dataset[field])\n",
        "    if not isinstance(tokenized, torch.Tensor):\n",
        "        tokenLengths = list(map(lambda sen: len(sen), tokenized['input_ids']))\n",
        "    else:\n",
        "        tokenLengths = [tensor.nonzero().size(0) for tensor in tokenized]\n",
        "    percentileLength = np.percentile(tokenLengths, percentile)\n",
        "    return int(percentileLength) + 1\n",
        "\n",
        "# Dont Touch This\n",
        "def TextEncoder(configs):\n",
        "    newModel = TE.TextTransformer(context_length=configs['reference_context_length'],\n",
        "                                 vocab_size=configs[\"reference_vocab_size\"],\n",
        "                                 width=configs[\"reference_width\"],\n",
        "                                 layers=configs[\"reference_layers\"],\n",
        "                                 heads=configs[\"reference_heads\"],\n",
        "                                 output_dim=configs[\"reference_embedding\"])\n",
        "    return newModel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee90637f",
      "metadata": {
        "id": "ee90637f",
        "papermill": {
          "duration": 0.016248,
          "end_time": "2024-12-18T17:14:15.854449",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.838201",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f75d675",
      "metadata": {
        "id": "7f75d675",
        "papermill": {
          "duration": 0.016386,
          "end_time": "2024-12-18T17:14:15.886639",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.870253",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### TODO: Compelete the Swish and LinearProjection functions based on the pydoc provided (15pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "83acbdd5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:15.920626Z",
          "iopub.status.busy": "2024-12-18T17:14:15.920377Z",
          "iopub.status.idle": "2024-12-18T17:14:15.927353Z",
          "shell.execute_reply": "2024-12-18T17:14:15.926669Z"
        },
        "id": "83acbdd5",
        "papermill": {
          "duration": 0.02619,
          "end_time": "2024-12-18T17:14:15.929057",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.902867",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Swish(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the Swish activation function.\n",
        "    Parameters:\n",
        "        beta (float, optional): The scaling parameter for the input x in the sigmoid\n",
        "                                function. Default is 1.0.\n",
        "    \"\"\"\n",
        "    def __init__(self, beta=1.0):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(self.beta * x)\n",
        "\n",
        "\n",
        "class LinearProjection(nn.Module):\n",
        "    \"\"\"\n",
        "    A projection layer with Swish activation, batch normalization, dropout, and residual connections.\n",
        "\n",
        "    This module takes an input tensor, applies a series of transformations, and produces an\n",
        "    output tensor of the same shape, making use of residual connections and layer normalization.\n",
        "\n",
        "    Parameters:\n",
        "        embedding_dim (int): The dimensionality of the input embeddings.\n",
        "        projection_dim (int, optional): The dimensionality of the projection. Default is\n",
        "                                        `configs['project_to']`.\n",
        "        dropout (float, optional): The dropout rate. Default is `configs['dropout']`.\n",
        "\n",
        "    Layers:\n",
        "        - projection: Linear layer that projects the input to the specified `projection_dim`.\n",
        "        - swish: Swish activation function with a fixed beta of 1.0.\n",
        "        - batch_norm: Batch normalization applied after projection.\n",
        "        - fc: Fully connected layer for further transformations.\n",
        "        - dropout: Dropout applied to the output of the fully connected layer.\n",
        "        - layer_norm: Layer normalization applied after residual connection.\n",
        "\n",
        "    Methods:\n",
        "        forward(x):\n",
        "            Applies the projection, activation, normalization, dropout, residual connection,\n",
        "            and layer normalization to the input tensor.\n",
        "\n",
        "    Example:\n",
        "        model = LinearProjection(embedding_dim=128, projection_dim=64, dropout=0.1)\n",
        "        output = model(input_tensor)\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim, projection_dim=configs['project_to'], dropout=configs['dropout']):\n",
        "        super(LinearProjection, self).__init__()\n",
        "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
        "        self.swish = Swish(beta=1.0)\n",
        "        self.batch_norm = nn.BatchNorm1d(projection_dim)\n",
        "        self.fc = nn.Linear(projection_dim, projection_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #TODO\n",
        "        x = self.projection(x)\n",
        "        x = self.swish(x)\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.layer_norm(x + x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ece3abb5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:15.962709Z",
          "iopub.status.busy": "2024-12-18T17:14:15.962465Z",
          "iopub.status.idle": "2024-12-18T17:14:15.967754Z",
          "shell.execute_reply": "2024-12-18T17:14:15.967000Z"
        },
        "id": "ece3abb5",
        "papermill": {
          "duration": 0.024135,
          "end_time": "2024-12-18T17:14:15.969481",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.945346",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class CandidateModel(nn.Module):\n",
        "    def __init__(self, model_name, unfreezeLayers, trainable=True):\n",
        "        super().__init__()\n",
        "        self.candidateProjection = LinearProjection(embedding_dim=configs[\"candidate_embedding\"])\n",
        "        self.configs = AutoConfig.from_pretrained(model_name)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.batchNorm = nn.BatchNorm1d(configs[\"candidate_embedding\"])\n",
        "        self.targetTokenIdx = configs[\"cls_token_index\"]\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        clsEmbed = getClsToken(output.last_hidden_state)\n",
        "        clsEmbed = self.batchNorm(clsEmbed)\n",
        "        clsEmbed = self.candidateProjection(flattenMiddle(clsEmbed))\n",
        "        return clsEmbed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e0dd33e",
      "metadata": {
        "id": "4e0dd33e",
        "papermill": {
          "duration": 0.015974,
          "end_time": "2024-12-18T17:14:16.001750",
          "exception": false,
          "start_time": "2024-12-18T17:14:15.985776",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d73eeb",
      "metadata": {
        "id": "92d73eeb",
        "papermill": {
          "duration": 0.015543,
          "end_time": "2024-12-18T17:14:16.033408",
          "exception": false,
          "start_time": "2024-12-18T17:14:16.017865",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### TODO: Compelete the calcLoss functions based on the pydoc provided (20pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c8e57071",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:16.065973Z",
          "iopub.status.busy": "2024-12-18T17:14:16.065709Z",
          "iopub.status.idle": "2024-12-18T17:14:16.072545Z",
          "shell.execute_reply": "2024-12-18T17:14:16.071909Z"
        },
        "id": "c8e57071",
        "papermill": {
          "duration": 0.024464,
          "end_time": "2024-12-18T17:14:16.074093",
          "exception": false,
          "start_time": "2024-12-18T17:14:16.049629",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def calcLoss(batch, referenceModel, candidateModel, temperature):\n",
        "    \"\"\"\n",
        "    Compute the loss and the number of correct predictions for a contrastive learning task.\n",
        "\n",
        "    This function calculates a symmetric cross-entropy loss between the embeddings\n",
        "    generated by a reference model and a candidate model. It also computes the\n",
        "    number of correct predictions based on the alignment of the embeddings.\n",
        "\n",
        "    Args:\n",
        "        batch (dict): A batch of data containing:\n",
        "            - \"candidate\" (torch.Tensor): Tokenized input for the candidate model.\n",
        "            - \"reference\" (torch.Tensor): Tokenized input for the reference model.\n",
        "        referenceModel (nn.Module): The model generating embeddings for the reference input.\n",
        "        candidateModel (nn.Module): The model generating embeddings for the candidate input.\n",
        "        temperature (float): A scaling factor to control the logits' sharpness during similarity calculation.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - loss (torch.Tensor): The computed symmetric cross-entropy loss.\n",
        "            - corrects (int): The number of correctly predicted alignments.\n",
        "\n",
        "    Notes:\n",
        "        - The embeddings are normalized to ensure their magnitudes do not impact similarity.\n",
        "        - Logits represent scaled cosine similarity between reference and candidate embeddings.\n",
        "        - The targets are identity matrices, assuming perfect alignment between reference and candidate inputs.\n",
        "\n",
        "    Example Usage:\n",
        "        batch = {\n",
        "            \"candidate\": tokenized_candidate,\n",
        "            \"reference\": tokenized_reference\n",
        "        }\n",
        "        loss, corrects = calcLoss(batch, reference_model, candidate_model, temperature=0.1)\n",
        "    \"\"\"\n",
        "    # Move tokenized inputs to the specified device\n",
        "    candidateTokenized = batch[\"candidate\"].to(configs[\"device\"])\n",
        "    referenceTokenized = batch[\"reference\"].to(configs[\"device\"])\n",
        "\n",
        "    # Generate embeddings from reference and candidate models\n",
        "    referenceEmbeds = referenceModel(referenceTokenized)\n",
        "    candidateEmbeds = candidateModel(\n",
        "        input_ids=candidateTokenized[\"input_ids\"],\n",
        "        attention_mask=candidateTokenized[\"attention_mask\"]\n",
        "    )\n",
        "\n",
        "    # Normalize embeddings to have unit length\n",
        "    referenceEmbeds = F.normalize(referenceEmbeds, p=2, dim=-1)\n",
        "    candidateEmbeds = F.normalize(candidateEmbeds, p=2, dim=-1)\n",
        "        #TODO\n",
        "    logits = torch.matmul(candidateEmbeds, referenceEmbeds.T) / temperature\n",
        "    labels = torch.arange(logits.size(0), device=logits.device)\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    corrects = (logits.argmax(dim=-1) == labels).sum().item()\n",
        "\n",
        "    return loss, corrects"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1b4edc",
      "metadata": {
        "id": "5f1b4edc",
        "papermill": {
          "duration": 0.015457,
          "end_time": "2024-12-18T17:14:16.105022",
          "exception": false,
          "start_time": "2024-12-18T17:14:16.089565",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### TODO: Fill the trainLoop and valLoop (5pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "05f0bf97",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:16.137553Z",
          "iopub.status.busy": "2024-12-18T17:14:16.137287Z",
          "iopub.status.idle": "2024-12-18T17:14:16.146093Z",
          "shell.execute_reply": "2024-12-18T17:14:16.145202Z"
        },
        "id": "05f0bf97",
        "papermill": {
          "duration": 0.027335,
          "end_time": "2024-12-18T17:14:16.147775",
          "exception": false,
          "start_time": "2024-12-18T17:14:16.120440",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def trainLoop(dataloader, models, referenceTokenizer, candidateTokenizer, optimizer, temperature):\n",
        "    models['candidateModel'].train()\n",
        "\n",
        "    totalLoss = 0.0\n",
        "    totalCorrects = 0\n",
        "\n",
        "    print(\"Training Starts!\")\n",
        "    for (index, pairs) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "\n",
        "        candidteTokenized = candidateTokenizer(getPersianDs(pairs), padding='max_length', truncation=True, return_tensors=\"pt\", max_length=configs[\"fa_tok_percentile\"])\n",
        "        referenceTextTokenized = referenceTokenizer(getEnglishDs(pairs))\n",
        "\n",
        "        batch = {\n",
        "            \"candidate\" : candidteTokenized,\n",
        "            \"reference\" : referenceTextTokenized\n",
        "        }\n",
        "\n",
        "        loss, corrects = calcLoss(batch, models['referenceModel'], models['candidateModel'], temperature)\n",
        "        totalCorrects += corrects\n",
        "        totalLoss += loss\n",
        "\n",
        "        # Optimization using backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avgLoss = totalLoss / len(dataloader.dataset)\n",
        "    avgAccuracy = totalCorrects / len(dataloader.dataset)\n",
        "\n",
        "    print(\"train loss\", avgLoss.to(\"cpu\").item())\n",
        "    print(\"train accuracy\", avgAccuracy)\n",
        "\n",
        "    return avgLoss, avgAccuracy\n",
        "\n",
        "def valLoop(dataloader, models, referenceTokenizer, candidateTokenizer, temperature):\n",
        "    models['candidateModel'].eval()\n",
        "\n",
        "    print(\"Testing Starts!\")\n",
        "    totalLoss = 0.0\n",
        "    totalCorrects = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (index, pairs) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "            candidteTokenized = candidateTokenizer(getPersianDs(pairs), padding='max_length', truncation=True, return_tensors=\"pt\", max_length=configs[\"fa_tok_percentile\"])\n",
        "            referenceTextTokenized = referenceTokenizer(getEnglishDs(pairs))\n",
        "\n",
        "            batch = {\n",
        "                \"candidate\" : candidteTokenized,\n",
        "                \"reference\" : referenceTextTokenized\n",
        "            }\n",
        "\n",
        "            loss, corrects = calcLoss(batch, models['referenceModel'], models['candidateModel'], temperature)\n",
        "\n",
        "            totalCorrects += corrects\n",
        "            totalLoss += loss\n",
        "\n",
        "    avgLoss = totalLoss / len(dataloader.dataset)\n",
        "    avgAccuracy = totalCorrects / len(dataloader.dataset)\n",
        "\n",
        "    print(\"test loss\", avgLoss.to(\"cpu\").item())\n",
        "    print(\"test accuracy\", avgAccuracy)\n",
        "\n",
        "    return avgLoss, avgAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f015a11f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:16.180038Z",
          "iopub.status.busy": "2024-12-18T17:14:16.179783Z",
          "iopub.status.idle": "2024-12-18T17:14:21.238541Z",
          "shell.execute_reply": "2024-12-18T17:14:21.237667Z"
        },
        "id": "f015a11f",
        "outputId": "d0a0083e-c13d-454d-c773-3399ff1123d5",
        "papermill": {
          "duration": 5.07707,
          "end_time": "2024-12-18T17:14:21.240389",
          "exception": false,
          "start_time": "2024-12-18T17:14:16.163319",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "b83e6b5867424c47885c8470960fe2f8",
            "1170b44de4da41b895f9b37e8d07d9c5",
            "2a7864d724e544428510c48ab7d1a719",
            "58c9fa9a5dea40969eea4fa5dcff1703",
            "2541dc99a1554d32a9500b5f6843d324",
            "495f35a6bd0d4ade868549e15c0fcc5d",
            "8395447da693413d97fac1950c51acb0",
            "1528ac3f206a4ffabe51f336f1384deb",
            "b2d970a1cd31416bb0b496795b6a9368",
            "d7a4f36aa27c47b1825abf781b00e0b6",
            "dc6e0d2b244647c4b87aeb44b43f7a5f",
            "cca16cebb3c645f6b0c37ff951456283",
            "03031d6506e84c8e962b94d91fcaf168",
            "fc19458658624877910eba7bbe283c12",
            "d5ae432dadbb4488903bd10d6c1e513a",
            "8e8070d5886a4acd91e929bfe66fc712",
            "79372d4000f64c74a7dd5a4be3250bb8",
            "36571211140d41da96c3413e3f3f3727",
            "83caadb6d9e6430caa435d45eb87061d",
            "8ed6a96593bb4bdbbaba12565341efeb",
            "0276226fd31e4b0baa0ec7df8c754859",
            "28ea177030cf40edb9098bbb79ce864c"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Preproccess:  {'en': 'A person doing karate in a green business card.', 'fa': 'شخصی که کاراته انجام می دهد در کارت ویزیت سبز.'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/59999 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b83e6b5867424c47885c8470960fe2f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cca16cebb3c645f6b0c37ff951456283"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Preproccess:  {'en': 'a person doing karate in a green business card', 'fa': 'شخصی که کاراته انجام می دهد در کارت ویزیت سبز'}\n"
          ]
        }
      ],
      "source": [
        "oldCols = [\"en\", \"fa\"]\n",
        "datasetTrain, datasetVal = getDatasetsCSV(oldCols[0], oldCols[1], configs[\"english\"], configs[\"persian\"], configs[\"train_path\"], configs[\"val_path\"])\n",
        "\n",
        "getPersianDs, getEnglishDs = getDsByLang(configs[\"persian\"], configs[\"english\"])\n",
        "print(\"Before Preproccess: \", datasetTrain[0])\n",
        "datasetTrain, datasetVal = applyPreprocess([datasetTrain, datasetVal], configs)\n",
        "print(\"After Preproccess: \", datasetTrain[0])\n",
        "trainDataloader = DataLoader(datasetTrain, batch_size=configs['batch_size'], shuffle=True)\n",
        "valDataloader = DataLoader(datasetVal, batch_size=configs['batch_size'], shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea3bc61",
      "metadata": {
        "id": "aea3bc61",
        "papermill": {
          "duration": 0.015811,
          "end_time": "2024-12-18T17:14:21.272664",
          "exception": false,
          "start_time": "2024-12-18T17:14:21.256853",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "506ef8ec",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:21.306272Z",
          "iopub.status.busy": "2024-12-18T17:14:21.306012Z",
          "iopub.status.idle": "2024-12-18T17:14:31.799786Z",
          "shell.execute_reply": "2024-12-18T17:14:31.798984Z"
        },
        "id": "506ef8ec",
        "outputId": "7f762b33-f15c-4618-ba6b-755b1d755198",
        "papermill": {
          "duration": 10.512708,
          "end_time": "2024-12-18T17:14:31.801887",
          "exception": false,
          "start_time": "2024-12-18T17:14:21.289179",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "referenceTokenizer = open_clip.get_tokenizer(configs[\"reference_checkPoint\"])\n",
        "\n",
        "candidateConfig = AutoConfig.from_pretrained(configs[\"candidate_checkpoint\"])\n",
        "candidateTokenizer = AutoTokenizer.from_pretrained(configs[\"candidate_checkpoint\"])\n",
        "\n",
        "configs = configs | {\"candidate_embedding\" : candidateConfig.hidden_size}\n",
        "\n",
        "faTokenPercentile = calcPrcentileTokens(datasetTrain, candidateTokenizer, configs[\"persian\"])\n",
        "faTokenPercentile\n",
        "\n",
        "enTokenPercentile = calcPrcentileTokens(datasetTrain, referenceTokenizer, configs[\"english\"])\n",
        "enTokenPercentile\n",
        "\n",
        "configs = configs | {\"en_tok_percentile\" : enTokenPercentile}\n",
        "configs = configs | {\"fa_tok_percentile\" : faTokenPercentile}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d92d790a",
      "metadata": {
        "id": "d92d790a",
        "papermill": {
          "duration": 0.016378,
          "end_time": "2024-12-18T17:14:31.835725",
          "exception": false,
          "start_time": "2024-12-18T17:14:31.819347",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0cfbc447",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:31.869333Z",
          "iopub.status.busy": "2024-12-18T17:14:31.869028Z",
          "iopub.status.idle": "2024-12-18T17:14:59.888895Z",
          "shell.execute_reply": "2024-12-18T17:14:59.887930Z"
        },
        "id": "0cfbc447",
        "papermill": {
          "duration": 28.039003,
          "end_time": "2024-12-18T17:14:59.891005",
          "exception": false,
          "start_time": "2024-12-18T17:14:31.852002",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "referenceModel = TextEncoder(configs).to(configs[\"device\"])\n",
        "candidateModel = CandidateModel(model_name=configs[\"candidate_checkpoint\"], unfreezeLayers=configs[\"unfreezed_layers\"]).to(configs[\"device\"])\n",
        "referenceModel = freezeModel(referenceModel)\n",
        "\n",
        "candidateModel.to(configs['device'])\n",
        "referenceModel.to(configs['device'])\n",
        "\n",
        "models = {\n",
        "    \"referenceModel\" : referenceModel,\n",
        "    \"candidateModel\" : candidateModel\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59bc9d96",
      "metadata": {
        "id": "59bc9d96",
        "papermill": {
          "duration": 0.0162,
          "end_time": "2024-12-18T17:14:59.924176",
          "exception": false,
          "start_time": "2024-12-18T17:14:59.907976",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Training\n",
        "### TODO (10pts) for running the code and (20pts) for achieving above 70 percent test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "03a0e5e7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:14:59.958682Z",
          "iopub.status.busy": "2024-12-18T17:14:59.958089Z",
          "iopub.status.idle": "2024-12-18T17:14:59.964595Z",
          "shell.execute_reply": "2024-12-18T17:14:59.963977Z"
        },
        "id": "03a0e5e7",
        "papermill": {
          "duration": 0.025563,
          "end_time": "2024-12-18T17:14:59.966213",
          "exception": false,
          "start_time": "2024-12-18T17:14:59.940650",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "temperature = torch.nn.Parameter(torch.tensor(configs['temperature']).float())\n",
        "optimizer = torch.optim.AdamW(list(models['candidateModel'].parameters()) + [temperature], weight_decay=configs[\"weight_decay\"], lr=configs['lr'])\n",
        "lrScheduler = ReduceLROnPlateau(optimizer, 'max', patience=configs['patience'], factor=configs['factor'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a7f783c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T17:15:00.001563Z",
          "iopub.status.busy": "2024-12-18T17:15:00.001314Z",
          "iopub.status.idle": "2024-12-18T22:11:22.427942Z",
          "shell.execute_reply": "2024-12-18T22:11:22.427024Z"
        },
        "id": "0a7f783c",
        "outputId": "8a9e4719-9ec0-4122-cd43-e5ce74d8abb0",
        "papermill": {
          "duration": 17782.445889,
          "end_time": "2024-12-18T22:11:22.429709",
          "exception": false,
          "start_time": "2024-12-18T17:14:59.983820",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Starts!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [40:17<00:00,  5.16s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.03782239183783531\n",
            "train accuracy 0.3146552442540709\n",
            "Testing Starts!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [12:05<00:00,  4.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test loss 0.03790127485990524\n",
            "test accuracy 0.5065\n",
            "Temperature at this epoch was : 19.947002410888672\n",
            "Training Starts!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [40:15<00:00,  5.15s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.037802357226610184\n",
            "train accuracy 0.588893148219137\n",
            "Testing Starts!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [12:05<00:00,  4.62s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test loss 0.03789237141609192\n",
            "test accuracy 0.65995\n",
            "Temperature at this epoch was : 19.895450592041016\n",
            "Training Starts!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [40:14<00:00,  5.15s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss 0.037794966250658035\n",
            "train accuracy 0.7046284104735079\n",
            "Testing Starts!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [12:05<00:00,  4.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss 0.03788699582219124\n",
            "test accuracy 0.711\n",
            "Temperature at this epoch was : 19.84465789794922\n",
            "Training Starts!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 26/469 [02:14<37:56,  5.14s/it]"
          ]
        }
      ],
      "source": [
        "bestValAcc = float('-inf')\n",
        "\n",
        "metrics = pd.DataFrame(columns=[\"Avg-train-loss\", \"Avg-train-accuracy\",\"Avg-val-loss\", \"Avg-val-accuracy\"])\n",
        "\n",
        "for t in range(configs['epochs']):\n",
        "    trainLoss, trainAcc = trainLoop(trainDataloader, models, referenceTokenizer, candidateTokenizer, optimizer, temperature)\n",
        "    valLoss, valAcc = valLoop(valDataloader, models, referenceTokenizer, candidateTokenizer, temperature)\n",
        "\n",
        "    metrics.loc[t+1] = [trainLoss.item(), trainAcc, valLoss.item(), valAcc]\n",
        "\n",
        "    lrScheduler.step(valAcc)\n",
        "\n",
        "    print(\"Temperature at this epoch was :\", temperature.item())\n",
        "\n",
        "print(f'Best accuracy of validation gained: ', bestValAcc)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "884ba162",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-18T22:11:22.772325Z",
          "iopub.status.busy": "2024-12-18T22:11:22.771986Z",
          "iopub.status.idle": "2024-12-18T22:11:23.076626Z",
          "shell.execute_reply": "2024-12-18T22:11:23.075718Z"
        },
        "id": "884ba162",
        "papermill": {
          "duration": 0.494729,
          "end_time": "2024-12-18T22:11:23.078241",
          "exception": false,
          "start_time": "2024-12-18T22:11:22.583512",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "plotMetric(metrics, \"Avg-val-accuracy\")\n",
        "metrics.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "732adf00",
      "metadata": {
        "id": "732adf00",
        "papermill": {
          "duration": 0.148084,
          "end_time": "2024-12-18T22:11:23.388751",
          "exception": false,
          "start_time": "2024-12-18T22:11:23.240667",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Question Box (10pts + 5pts bonus)\n",
        "\n",
        "1- Do we even need normalization for tasks like this? will they provide any accuracy gain? write what you think.\n",
        "\n",
        "Normalization plays a vital role in many machine learning tasks, depending on the use case. Here’s why:\n",
        "\n",
        "Yes. Normalization is still likely to provide benefits, though the impact might not be as large as in a full-scale CLIP training setup.\n",
        "\n",
        "**Accuracy Impact:** While the dataset in this task is smaller and the batch size is reduced, normalization is still likely to provide some accuracy gains. Because normalization will help the model converge more quickly and make more meaningful comparisons during contrastive learning. Additionally, as smaller batch sizes can introduce more variance, normalization helps mitigate this issue and keeps the training stable.\n",
        "\n",
        "---\n",
        "\n",
        "2- When training a neural network, what takes the memory? mention at least 4 things.\n",
        "\n",
        "Four key components that contribute to memory usage are the following:\n",
        "\n",
        "**Model Weights:** The memory required to store the trainable parameters, such as weights and biases across all layers.\n",
        "\n",
        "**Intermediate Activations:** The output of each layer (activations) must be stored during forward propagation to be used later during backpropagation.\n",
        "\n",
        "**Gradients:** Memory is needed to store gradients of all parameters, calculated during backpropagation for optimization.\n",
        "\n",
        "**Optimizer States:** Some optimizers, such as Adam or RMSProp, store additional data like momentum and learning rate adjustments, which increase memory demand.\n",
        "\n",
        "Other contributing factors include the batch size (larger batches require more memory for storing inputs and activations) and temporary buffers used during computations like matrix multiplications.\n",
        "\n",
        "---\n",
        "3- find out the actual Open Ai's training configuration of Clip model.\n",
        "\n",
        "OpenAI’s CLIP (Contrastive Language–Image Pretraining) model is trained using the following setup:\n",
        "\n",
        "**-** Dataset: A large-scale dataset comprising image-text pairs sourced from the internet.\n",
        "\n",
        "**-** Model Architecture:\n",
        "- Vision Encoder: ResNet-50 or a Vision Transformer (ViT).\n",
        "- Text Encoder: A Transformer-based architecture with tokenization similar to BERT.\n",
        "\n",
        "**-** Objective Function: Contrastive loss, aligning image and text embeddings within a shared feature space.\n",
        "\n",
        "**-** Batch Size: Extremely large batches, such as 32,768, to effectively compute the contrastive loss.\n",
        "\n",
        "**-** Optimizer: Adam with weight decay for efficient learning.\n",
        "\n",
        "**-** Learning Rate: Scheduled using a cosine annealing approach with a warmup phase.\n",
        "\n",
        "**-** Data Augmentation: Comprehensive image augmentations to enhance robustness.\n",
        "\n",
        "**-** Training Resources: High computational power, leveraging hundreds of GPUs or TPUs for an extended training period.\n",
        "\n",
        "This configuration supports effective learning and robust alignment between image and text modalities.\n",
        "\n",
        "---\n",
        "#### Bonus\n",
        "4- We have an alternative clip's loss implementation, write its pseudocode.\n",
        "\n",
        "Here’s a pseudocode for an alternative implementation of CLIP’s contrastive loss:\n",
        "\n",
        "```python\n",
        "function contrastive_loss(image_features, text_features, temperature):\n",
        "    normalized_image_embeddings = normalize(image_embeddings)\n",
        "    normalized_text_embeddings = normalize(text_embeddings)\n",
        "    similarity_matrix = dot_product(normalized_image_embeddings, normalized_text_embeddings.T) / temperature\n",
        "    positive_loss = -log(softmax(diag(similarity_matrix)))\n",
        "    negative_loss = 0\n",
        "    for i in range(len(image_embeddings)):\n",
        "        negative_similarities = similarity_matrix[i]\n",
        "        negative_similarities = negative_similarities[i] = -float('inf')\n",
        "        negative_loss += -log(softmax(negative_similarities))\n",
        "    total_loss = positive_loss + negative_loss\n",
        "    return total_loss\n",
        "```\n",
        "This implementation computes separate losses for image-to-text and text-to-image alignments, ensuring a balanced optimization for both modalities."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4600270,
          "sourceId": 7845742,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4600399,
          "sourceId": 7845904,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30805,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 17879.671693,
      "end_time": "2024-12-18T22:11:27.581599",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-12-18T17:13:27.909906",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b83e6b5867424c47885c8470960fe2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1170b44de4da41b895f9b37e8d07d9c5",
              "IPY_MODEL_2a7864d724e544428510c48ab7d1a719",
              "IPY_MODEL_58c9fa9a5dea40969eea4fa5dcff1703"
            ],
            "layout": "IPY_MODEL_2541dc99a1554d32a9500b5f6843d324"
          }
        },
        "1170b44de4da41b895f9b37e8d07d9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_495f35a6bd0d4ade868549e15c0fcc5d",
            "placeholder": "​",
            "style": "IPY_MODEL_8395447da693413d97fac1950c51acb0",
            "value": "Map: 100%"
          }
        },
        "2a7864d724e544428510c48ab7d1a719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1528ac3f206a4ffabe51f336f1384deb",
            "max": 59999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2d970a1cd31416bb0b496795b6a9368",
            "value": 59999
          }
        },
        "58c9fa9a5dea40969eea4fa5dcff1703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7a4f36aa27c47b1825abf781b00e0b6",
            "placeholder": "​",
            "style": "IPY_MODEL_dc6e0d2b244647c4b87aeb44b43f7a5f",
            "value": " 59999/59999 [00:04&lt;00:00, 9827.13 examples/s]"
          }
        },
        "2541dc99a1554d32a9500b5f6843d324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "495f35a6bd0d4ade868549e15c0fcc5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8395447da693413d97fac1950c51acb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1528ac3f206a4ffabe51f336f1384deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d970a1cd31416bb0b496795b6a9368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7a4f36aa27c47b1825abf781b00e0b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6e0d2b244647c4b87aeb44b43f7a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cca16cebb3c645f6b0c37ff951456283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03031d6506e84c8e962b94d91fcaf168",
              "IPY_MODEL_fc19458658624877910eba7bbe283c12",
              "IPY_MODEL_d5ae432dadbb4488903bd10d6c1e513a"
            ],
            "layout": "IPY_MODEL_8e8070d5886a4acd91e929bfe66fc712"
          }
        },
        "03031d6506e84c8e962b94d91fcaf168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79372d4000f64c74a7dd5a4be3250bb8",
            "placeholder": "​",
            "style": "IPY_MODEL_36571211140d41da96c3413e3f3f3727",
            "value": "Map: 100%"
          }
        },
        "fc19458658624877910eba7bbe283c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83caadb6d9e6430caa435d45eb87061d",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ed6a96593bb4bdbbaba12565341efeb",
            "value": 20000
          }
        },
        "d5ae432dadbb4488903bd10d6c1e513a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0276226fd31e4b0baa0ec7df8c754859",
            "placeholder": "​",
            "style": "IPY_MODEL_28ea177030cf40edb9098bbb79ce864c",
            "value": " 20000/20000 [00:01&lt;00:00, 14787.46 examples/s]"
          }
        },
        "8e8070d5886a4acd91e929bfe66fc712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79372d4000f64c74a7dd5a4be3250bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36571211140d41da96c3413e3f3f3727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83caadb6d9e6430caa435d45eb87061d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed6a96593bb4bdbbaba12565341efeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0276226fd31e4b0baa0ec7df8c754859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ea177030cf40edb9098bbb79ce864c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}